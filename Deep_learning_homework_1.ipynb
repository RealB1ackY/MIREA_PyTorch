{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqyr9mAU0WCLUD7QiR9vME",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealB1ackY/MIREA_PyTorch/blob/main/Deep_learning_homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6Jkby9g1GtDZ",
        "outputId": "6c6ad8bf-82d0-4fed-b234-62da98759bdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__ "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ДЗ_01: neuron(neuron(1 * x1 + 1 * x2 - 0) - neuron(1 * x1 + 1 * x2 - 1))"
      ],
      "metadata": {
        "id": "aPqMZaezUMLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3skzhBgJJ2Y1",
        "outputId": "bb27d8e7-1a9a-4eca-b471-dc0083af3297"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xs = torch.tensor([[1,1], [1, 0], [0, 1], [0, 0]], dtype=torch.float32)\n",
        "Xy = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "KvfrnyXMKFpn"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "class XORModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(2, 2),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(2, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.optimizer = Adam(self.parameters())\n",
        "    self.loss = nn.MSELoss()\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.layers(X)\n",
        "\n",
        "  def fit(self, X, y_true):\n",
        "    self.optimizer.zero_grad()\n",
        "    y_pred = self.forward(X)\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "6Du8oPKOK8H8"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xor_model = XORModel()"
      ],
      "metadata": {
        "id": "-soXnEguMLw2"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xor_model(Xs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qZnJXbpQKCH",
        "outputId": "481f1bbd-91f5-4cda-de21-d8bcb56b4804"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3370],\n",
              "        [0.3192],\n",
              "        [0.3377],\n",
              "        [0.3195]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100000\n",
        "for i in range(EPOCHS):\n",
        "  if i % 1000 == 0:\n",
        "    loss = xor_model.fit(Xs, Xy)\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSt6LXmMUDND",
        "outputId": "7314d09c-478d-499f-8157-5834b65cf58a"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27943775057792664\n",
            "0.2792511582374573\n",
            "0.27906495332717896\n",
            "0.27887922525405884\n",
            "0.2786939740180969\n",
            "0.2785091996192932\n",
            "0.2783248722553253\n",
            "0.278141051530838\n",
            "0.2779577374458313\n",
            "0.2777749300003052\n",
            "0.27759265899658203\n",
            "0.2774108946323395\n",
            "0.2772296667098999\n",
            "0.2770489752292633\n",
            "0.27686887979507446\n",
            "0.2766893208026886\n",
            "0.2765103280544281\n",
            "0.27633190155029297\n",
            "0.2761540710926056\n",
            "0.27597683668136597\n",
            "0.2758001685142517\n",
            "0.27562415599823\n",
            "0.2754487097263336\n",
            "0.275273859500885\n",
            "0.2750996947288513\n",
            "0.27492615580558777\n",
            "0.274753212928772\n",
            "0.2745809257030487\n",
            "0.27440929412841797\n",
            "0.2742382287979126\n",
            "0.2740679085254669\n",
            "0.2738981544971466\n",
            "0.273729145526886\n",
            "0.2735607624053955\n",
            "0.27339303493499756\n",
            "0.2732260525226593\n",
            "0.2730596661567688\n",
            "0.2728939950466156\n",
            "0.27272897958755493\n",
            "0.2725646495819092\n",
            "0.27240100502967834\n",
            "0.2722380757331848\n",
            "0.2720758318901062\n",
            "0.2719142436981201\n",
            "0.2717534005641937\n",
            "0.27159324288368225\n",
            "0.2714337408542633\n",
            "0.27127498388290405\n",
            "0.2711169421672821\n",
            "0.2709595263004303\n",
            "0.27080291509628296\n",
            "0.27064695954322815\n",
            "0.27049171924591064\n",
            "0.27033716440200806\n",
            "0.27018335461616516\n",
            "0.2700302302837372\n",
            "0.2698778510093689\n",
            "0.2697261571884155\n",
            "0.26957520842552185\n",
            "0.2694249451160431\n",
            "0.26927536725997925\n",
            "0.2691265642642975\n",
            "0.26897841691970825\n",
            "0.2688310444355011\n",
            "0.26868435740470886\n",
            "0.2685384154319763\n",
            "0.2683931589126587\n",
            "0.26824861764907837\n",
            "0.26810482144355774\n",
            "0.267961710691452\n",
            "0.267819344997406\n",
            "0.2676776945590973\n",
            "0.2675367593765259\n",
            "0.2673965394496918\n",
            "0.26725706458091736\n",
            "0.26711827516555786\n",
            "0.26698020100593567\n",
            "0.2668428421020508\n",
            "0.266706258058548\n",
            "0.2665703296661377\n",
            "0.2664351165294647\n",
            "0.26630064845085144\n",
            "0.2661668658256531\n",
            "0.2660338282585144\n",
            "0.26590150594711304\n",
            "0.2657698690891266\n",
            "0.26563897728919983\n",
            "0.265508770942688\n",
            "0.26537930965423584\n",
            "0.265250563621521\n",
            "0.26512250304222107\n",
            "0.26499518752098083\n",
            "0.26486852765083313\n",
            "0.2647426128387451\n",
            "0.264617383480072\n",
            "0.2644928991794586\n",
            "0.26436910033226013\n",
            "0.26424601674079895\n",
            "0.26412367820739746\n",
            "0.2640019655227661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ДЗ_02:"
      ],
      "metadata": {
        "id": "RWZJQBhuptM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "b = torch.tensor([4.0], requires_grad=True)\n",
        "c = torch.tensor([1.0], requires_grad=True)\n",
        "d = torch.tensor([5.0], requires_grad=False)"
      ],
      "metadata": {
        "id": "rHAT-rNxnh-X"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHtu7lZ4b1kf",
        "outputId": "7e39101b-a320-48ed-ad78-038f5d3f5637"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = a * b + c * d\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "EIptMRSCb667"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)\n",
        "print(b.grad)\n",
        "print(c.grad)\n",
        "print(d.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW7UAZWwcGGh",
        "outputId": "8c09928f-7836-4b07-9215-683b54f902b7"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.])\n",
            "tensor([2.])\n",
            "tensor([5.])\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}